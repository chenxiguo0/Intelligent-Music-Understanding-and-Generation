{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89dd3add",
   "metadata": {},
   "source": [
    "# Audio Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d96cd",
   "metadata": {},
   "source": [
    "## Simplified Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2fb8b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended audio:\n",
      "audio\\bass_synthetic_033-044-050.wav\n",
      "audio\\bass_synthetic_098-036-050.wav\n",
      "audio\\bass_synthetic_033-035-050.wav\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load JSON metadata\n",
    "with open(\"../data/examples.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare file paths and tag vectors\n",
    "file_paths = []\n",
    "tag_vectors = []\n",
    "\n",
    "for note_id, item in data.items():\n",
    "    # Construct the full relative audio path (assuming all files in ./audio/)\n",
    "    audio_path = os.path.join(\"audio\", note_id + \".wav\")\n",
    "    file_paths.append(audio_path)\n",
    "\n",
    "    # Vector = [10-dimensional qualities] + [source] + [velocity]\n",
    "    vector = item[\"qualities\"] + [item[\"instrument_source\"], item[\"velocity\"]]\n",
    "    tag_vectors.append(vector)\n",
    "\n",
    "X = np.array(tag_vectors)\n",
    "\n",
    "# Fit nearest neighbor model\n",
    "knn = NearestNeighbors(n_neighbors=3, metric=\"euclidean\")\n",
    "knn.fit(X)\n",
    "\n",
    "# Define recommendation function\n",
    "def recommend_audio(quality_vector, source, velocity, top_k=3):\n",
    "    # Build query vector\n",
    "    query = quality_vector + [source, velocity]\n",
    "    query_vec = np.array([query])\n",
    "\n",
    "    # Get nearest neighbors\n",
    "    distances, indices = knn.kneighbors(query_vec, n_neighbors=top_k)\n",
    "\n",
    "    # Return file paths\n",
    "    return [file_paths[i] for i in indices[0]]\n",
    "\n",
    "# Example: Recommend audio with a dark quality, synthetic source, and medium velocity\n",
    "quality_query = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  # e.g. \"dark\"\n",
    "recommended = recommend_audio(quality_query, source=2, velocity=50)\n",
    "\n",
    "# Print results\n",
    "print(\"Recommended audio:\")\n",
    "for path in recommended:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5beb5f",
   "metadata": {},
   "source": [
    "## Advanced recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1b058",
   "metadata": {},
   "source": [
    "### Step 1: Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470673bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "with open(\"../data/examples.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3611cc14",
   "metadata": {},
   "source": [
    "### Step 2: Define mappings and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02744398",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_labels = [\n",
    "    \"bright\", \"dark\", \"distortion\", \"fast_decay\", \"long_release\",\n",
    "    \"multiphonic\", \"nonlinear_env\", \"percussive\", \"reverb\", \"tempo_synced\"\n",
    "]\n",
    "source_map = {\"acoustic\": 0, \"electronic\": 1, \"synthetic\": 2}\n",
    "velocity_map = {\"low\": 30, \"medium\": 75, \"high\": 120}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8851b6",
   "metadata": {},
   "source": [
    "### Step 3: Prepare vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e067de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='euclidean', n_neighbors=3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths, tag_vectors, note_ids = [], [], []\n",
    "\n",
    "for note_id, item in data.items():\n",
    "    file_paths.append(os.path.join(\"audio\", note_id + \".wav\"))\n",
    "    note_ids.append(note_id)\n",
    "    vector = item[\"qualities\"] + [item[\"instrument_source\"], item[\"velocity\"]]\n",
    "    tag_vectors.append(vector)\n",
    "\n",
    "X = np.array(tag_vectors)\n",
    "knn = NearestNeighbors(n_neighbors=3, metric=\"euclidean\")\n",
    "knn.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab9033",
   "metadata": {},
   "source": [
    "### Step 4: Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b0e2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_query(qualities_str, source_str, velocity_str):\n",
    "    quality_vector = [1 if q in qualities_str else 0 for q in quality_labels]\n",
    "    source = source_map[source_str]\n",
    "    velocity = velocity_map[velocity_str]\n",
    "    return quality_vector + [source, velocity]\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a580c306",
   "metadata": {},
   "source": [
    "### Step 5: Widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d5a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_selector = widgets.SelectMultiple(\n",
    "    options=quality_labels,\n",
    "    value=[\"dark\"],\n",
    "    description=\"Qualities:\",\n",
    "    layout=widgets.Layout(width=\"300px\", height=\"120px\")\n",
    ")\n",
    "\n",
    "source_dropdown = widgets.Dropdown(\n",
    "    options=list(source_map.keys()),\n",
    "    value=\"synthetic\",\n",
    "    description=\"Source:\"\n",
    ")\n",
    "\n",
    "velocity_dropdown = widgets.Dropdown(\n",
    "    options=list(velocity_map.keys()),\n",
    "    value=\"medium\",\n",
    "    description=\"Velocity:\"\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd1c90a",
   "metadata": {},
   "source": [
    "### Step 6: Main callback function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3586e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_recommend_click(_):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        # --- 1. Query vector ---\n",
    "        query_vec = encode_query(\n",
    "            quality_selector.value,\n",
    "            source_dropdown.value,\n",
    "            velocity_dropdown.value\n",
    "        )\n",
    "        distances, indices = knn.kneighbors([query_vec], n_neighbors=3)\n",
    "\n",
    "        print(\"üéß Recommended Audio Files:\")\n",
    "        similarities = []\n",
    "        for i in indices[0]:\n",
    "            sim = cosine_similarity(query_vec, X[i])\n",
    "            similarities.append(sim)\n",
    "            path = file_paths[i]\n",
    "            print(f\"{note_ids[i]} | similarity: {sim:.3f}\")\n",
    "            if os.path.exists(path):\n",
    "                display(Audio(path))\n",
    "\n",
    "        # --- 2. Cosine similarity table ---\n",
    "        table = pd.DataFrame({\n",
    "            \"Note ID\": [note_ids[i] for i in indices[0]],\n",
    "            \"Cosine Similarity\": similarities\n",
    "        })\n",
    "        display(table)\n",
    "\n",
    "        # --- 3. PCA visualization ---\n",
    "        X_2d = PCA(n_components=2).fit_transform(X)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.scatter(X_2d[:, 0], X_2d[:, 1], alpha=0.3, label=\"All Samples\")\n",
    "        plt.scatter(X_2d[indices[0], 0], X_2d[indices[0], 1], color='red', label=\"Recommended\")\n",
    "        plt.title(\"PCA: NSynth Tag Space with Recommendations Highlighted\")\n",
    "        plt.xlabel(\"PC1\")\n",
    "        plt.ylabel(\"PC2\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70989cc3",
   "metadata": {},
   "source": [
    "### Step 7: Display UI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345c9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cb644b3c5d416ab3bfa76254eb9a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(SelectMultiple(description='Qualities:', index=(1,), layout=Layout(height='120px', width='300px‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommend_button = widgets.Button(description=\"üéß Recommend\")\n",
    "recommend_button.on_click(on_recommend_click)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    quality_selector,\n",
    "    source_dropdown,\n",
    "    velocity_dropdown,\n",
    "    recommend_button,\n",
    "    output_area\n",
    "])\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f98b47",
   "metadata": {},
   "source": [
    "## Analysis of the Music Recommendation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e641970",
   "metadata": {},
   "source": [
    "The recommender system demonstrated strong performance in returning relevant audio samples based on the selected tags. In the example shown, the user requested sounds with the qualities ‚Äúdark,‚Äù a ‚Äúelectronic‚Äù source, and ‚Äúhigh‚Äù velocity. The system instantly provided three top recommendations‚Äîorgan_electronic_113-054-127, organ_electronic_001-060-127, and organ_electronic_057-056-127‚Äîall with a cosine similarity score of 1.0. This perfect similarity suggests that these samples match the input tag vector exactly, confirming the system‚Äôs ability to find highly relevant matches in the dataset.\n",
    "\n",
    "The accompanying PCA visualization provides additional insight into the recommendation process. Here, all dataset samples are plotted in a reduced two-dimensional tag space, with the recommended items highlighted in red. The red dots sit squarely within the overall data distribution, illustrating that the recommended clips are not outliers, but rather representative examples from the relevant region of the feature space. This means the recommender is not only precise in matching user-specified tags, but also consistent in navigating the entire dataset.\n",
    "\n",
    "Overall, these results show that the tag-based KNN approach is highly effective for interactive music search. The system responds instantly, provides intuitive control via tags, and its recommendations are both accurate and explainable‚Äîmaking it a practical tool for musicians or sound designers looking for just the right sound. The visualization further builds trust, showing that the system‚Äôs choices are well-supported by the underlying data distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
